\documentclass[a4paper,11pt]{article}
\usepackage[T1]{fontenc}
\usepackage[polish]{babel}
\usepackage[utf8]{inputenc}
\usepackage{lmodern}
\usepackage{pgfplots}
\selectlanguage{polish}
\usepackage{geometry}
\usepackage{listings}
\newgeometry{tmargin=3cm, bmargin=3cm, lmargin=2.5cm, rmargin=2.5cm}
\title{
	\textbf{Programowanie równoległe i rozproszone}\vspace{40pt}
	\\\textit{Politechnika Krakowska} \\\vspace{40pt}
	Laboratorium 2
	\vspace{300pt}

}
\author{
	Paweł Suchanicz,\\
	Rafał Niemczyk
}
\begin{document}
\begin{titlepage}
\maketitle
\end{titlepage}

\begin{center}
\tableofcontents
\end{center}
\newpage
\section{Wstęp}
\subsection{Opis laboratorium}
\paragraph{}Celem laboratorium było wykorzystanie standardu MPI do zrównoleglenia kodu C++. MPI (Message Passing Interface) to standard przesyłania komunikatów pomiędzy procesami.
\paragraph{}Algorytmy, które są implementowane a następnie zrównoleglane w ramach laboratorium to normalizacja min-max, standaryzacja rozkładem normalnym i klasyfikacja KNN (k-najbliższych sąsiadów). Zaimplementowany KNN  uwzględnia jednego sąsiada i używa metryki euklidesowej.
\paragraph{}Szybkość działania każdego algorytmu została zmierzona dla implementacji sekwencyjnej w C++, implementacji równoległej w C++ dla różnej ilości procesów (1-8) oraz implementacji w Python (ze skorzystaniem z funkcji z pakietu scikit-learn).
\subsection{Specyfikacja sprzętowa}
\paragraph{}Przy pomiarach szybkości wykonywania algorytmów wykorzystany był sprzęt w konfiguracji:
\begin{itemize}
\item Procesor: Intel Core i7-4712MQ 4 x 2.30GHz
\item Ram: 8GB DDR3
\item System: Linux (Fedora 22)
\end{itemize}
\subsection{Zbiór danych} 
\paragraph{}Wykorzystany został zbiór obrazów ręcznie pisanych cyfr MNIST. Zbiór danych ma format .csv i zawiera 60000 rekordów, gdzie każdy rekord odpowiada za jeden obrazek 28x28 pikseli w skali szarości. Pierwsza wartość w rekordzie jest cyfrą która widnieje na obrazku, a kolejne to wartości pikseli obrazka. 
\paragraph{}
Dla zadań postawionych w laboratorium zbiór danych jest dość duży, więc został on obcięty do pierwszych 6000 rekordów, z czego 4500 przeznaczono do trenowania, a pozostałe 1500 do testowania.
\newpage    
\section{Wyniki}   
\subsection{Normalizacja min-max} 
\paragraph{}Wzór:
\paragraph{}$x^*=\frac{x-min(x)}{max(x)-min(x)}$
\subsubsection{Implementacja} 
\paragraph{}W C++ normalizacja została samodzielnie zgodnie z podanym powyżej wzorem. W pętli przechodzącej tablicy (po kolumnach) wyszukiwane są wartości minimum i maxium dla każdej kolumny a następnie wyliczana nowa wartość dla każdego z elementów tablicy.

\paragraph{}W Pythonie użyta została funkcja MinMaxScaler z pakietu sklearn .
\subsubsection{Porównanie wyników} 
\paragraph{}
\begin{tabular}{|c|c|}
\hline Parametry&Czas [s] \\ 
\hline C++ & 0.101 \\
\hline C++ MPI 1 proces& 0.255 \\
\hline C++ MPI 2 procesy& 0.184 \\
\hline C++ MPI 3 procesy& 0.177 \\
\hline C++ MPI 4 procesy& 0.160 \\
\hline C++ MPI 5 procesów& 0.165 \\
\hline C++ MPI 6 procesów& 0.156 \\
\hline C++ MPI 7 procesów& 0.158 \\
\hline C++ MPI 8 procesów& 0.172 \\
\hline
\hline Pyhon sklearn& 0.037 \\
\hline
\end{tabular}
\paragraph{}
Po zastosowaniu MPI i zwiększeniu ilości używanych procesów widać poprawę czasu wykonania. Czas wykonania spada gdy liczba procesów <= 4 (ilość rdzeni procesora na którym wykonywane były obliczenia). Nie udało się uzyskać czasu mniejszego niż z użyciem sklearn.
Po zastosowaniu MPI można zauważyć spory wzrost czasu wykonania (0.154 sekundy co stanowi 152 początkowego czasu). Związane to jest z narzutem jaki spowodowało użycie funkcji $MPI\_Scatter$ oraz $MPI\_Gather$. Przy zwiększeniu ilości używanych procesów widać poprawę czasu wykonania. Czas wykonania spada gdy liczba procesów <= 4 (ilość rdzeni procesora na którym wykonywane były obliczenia). Nie udało się uzyskać czasu mniejszego niż z użyciem sklearn.
\\
\begin{tikzpicture}[scale=1.5]
\begin{axis}[
title={Zależność czasu od ilości procesów - normalizacja},
title style={text width=16em},
xlabel={Ilość procesów},
ylabel={Czas [s]},
xmin=0,xmax=9,
ymin=0.14,ymax=0.28,
legend pos=north east,
ymajorgrids=true,grid style=dashed
]

\addplot[color=red,mark=*]
coordinates {
(1,0.255)
(2,0.184)
(3,0.177)
(4,0.160)
(5,0.165)
(6,0.156)
(7,0.158)
(8,0.172)
};

\legend{C++}
\end{axis}
\end{tikzpicture}
\paragraph{}
\begin{tikzpicture}[scale=1.5]
\begin{axis}[
title={Zależność przyspieszenia od ilości procesów - normalizacja},
title style={text width=16em},
xlabel={Ilość wątków},
ylabel={Czas [s]},
xmin=0,xmax=9,
ymin=-0.01,ymax=0.12,
legend pos=north east,
ymajorgrids=true,grid style=dashed
]

\addplot[color=red,mark=*]
coordinates {
(1,0)
(2,0.071)
(3,0.078)
(4,0.095)
(5,0.090)
(6,0.099)
(7,0.097)
(8,0.083)
};

\legend{C++}
\end{axis}
\end{tikzpicture}
\newpage

\subsection{Standaryzacja rozkładem normalnym} 
\paragraph{} Wzór:
\paragraph{}$x^*=\frac{x-\mu}{\sigma}$
\subsubsection{Implementacja} 
\paragraph{}W C++ standaryzacja została zaimplementowana samodzielnie zgodnie z podanym powyżej wzorem. Przechodzimy w pętli po kolumnach i dla każdej kolumny szukamy wartości średniej i wariancji, a następnie wyliczamy nowe wartości dla każdego elementu tablicy.

\paragraph{}W Pythonie użyta została funkcja StandardScaler z pakietu sklearn.

\subsubsection{Porównanie wyników} 

\paragraph{}
\begin{tabular}{|c|c|}
\hline Parametry&Czas [s] \\
\hline C++ & 0.157 \\
\hline C++ MPI 1 proces& 0.284 \\
\hline C++ MPI 2 procesy& 0.210 \\
\hline C++ MPI 3 procesy& 0.183 \\
\hline C++ MPI 4 procesy& 0.174 \\
\hline C++ MPI 5 procesów& 0.161 \\
\hline C++ MPI 6 procesów& 0.165 \\
\hline C++ MPI 7 procesów& 0.161 \\
\hline C++ MPI 8 procesów& 0.163 \\
\hline
\hline Pyhon sklearn& 0.086 \\
\hline
\end{tabular}
\paragraph{}
Podobnie jak w przypadku normalizacji samo użycie MPI spowodowało dość duży narzut (w stosunku do czasu w jakim wykonuje się normalizacja). Samo zwiększanie liczby procesów jednak przynosiło pozytywne skutki. Czas wykonania spadł o 38\% przy użyciu czterech wątków w stosunku do czasu działania algorytmu na jednym wątku z użyciem MPI. Czas pozostał jednak większy niż w sklearn z powodu narzutu MPI.

\begin{tikzpicture}[scale=1.5]
\begin{axis}[
title={Zależność czasu od ilości procesów - standaryzacja},
title style={text width=16em},
xlabel={Ilość procesów},
ylabel={Czas [s]},
xmin=0,xmax=9,
ymin=0.14,ymax=0.3,
legend pos=north east,
ymajorgrids=true,grid style=dashed
]
\addplot[color=red,mark=*]
coordinates {
(1,0.284)
(2,0.210)
(3,0.183)
(4,0.174)
(5,0.161)
(6,0.165)
(7,0.161)
(8,0.163)
};

\legend{C++}
\end{axis}
\end{tikzpicture}
\paragraph{}
\begin{tikzpicture}[scale=1.5]
\begin{axis}[
title={Zależność przyspieszenia od ilości procesów - standaryzacja},
title style={text width=16em},
xlabel={Ilość procesów},
ylabel={Czas [s]},
xmin=0,xmax=9,
ymin=-0.01,ymax=0.16,
legend pos=north east,
ymajorgrids=true,grid style=dashed
]

\addplot[color=red,mark=*]
coordinates {
(1, 0)
(2,0.074)
(3,0.101)
(4,0.11)
(5,0.123)
(6,0.119)
(7,0.123)
(8,0.121)
};

\legend{C++}
\end{axis}
\end{tikzpicture}
\newpage
\subsection{Klasyfikacja KNN} 
\subsubsection{Implementacja} 
\paragraph{}W C++ algorytm k najbliższych sąsiadów zaimplementowany samodzielnie. Algorytm uwzględnia tylko najbliższego sąsiada i korzysta z metryki euklidesowej.

\paragraph{}W Pythonie użyta została funkcja KNeighborsClassifier z pakietu sklearn z parametrami:
\begin{lstlisting}
KNeighborsClassifier(n_neighbors=1, algorithm='brute', p=2, metric='minkowski',
n_jobs=app_conf['jobs_number'])
\end{lstlisting}
Czasy były mierzone dla wartości njobs od 1 do 4. \\
Dokładność accuracy wyniosła 71\% dla danych po standard scalerze oraz 66\% dla danych po min-max scalarze.  
W przypadku normalizacji w c++ otrzymano dokładność 91.67\%. W przypadku standaryzacji dokładność wyniosła 90\%.
Można wysnuć wniosek, że algorytm w pakiecie sklearn działa w nieco inny sposób stąd mniejszy czas wykonania, ale i mniejsza dokładność. Użycie równoległości oczywiście nie miało wpływu na dokładność działania Knn.
\subsubsection{Porównanie wyników} 
\paragraph{}
\begin{tabular}{|c|c|}
\hline Parametry&Czas [s] \\ 
\hline C++ MPI 1 proces normalizacja& 16.673 \\
\hline C++ MPI 2 procesy normalizacja& 8.531 \\
\hline C++ MPI 3 procesy normalizacja& 6.299  \\
\hline C++ MPI 4 procesy normalizacja& 5.536 \\
\hline C++ MPI 5 procesów normalizacja& 5.470 \\
\hline C++ MPI 6 procesów normalizacja& 5.283 \\
\hline C++ MPI 7 procesów normalizacja& 5.069  \\
\hline C++ MPI 8 procesów normalizacja& 4.661 \\\hline
\hline Pyhon sklearn njobs=1 normalizacja& 0.215 \\
\hline Pyhon sklearn njobs=2 normalizacja& 0.323 \\
\hline Pyhon sklearn njobs=3 normalizacja& 0.455 \\
\hline Pyhon sklearn njobs=4 normalizacja& 0.386 \\\hline
\hline C++ MPI 1 proces standaryzacja& 16.638 \\
\hline C++ MPI 2 procesy standaryzacja& 8.631 \\ 
\hline C++ MPI 3 procesy standaryzacja& 6.136 \\ 
\hline C++ MPI 4 procesy standaryzacja& 5.081 \\
\hline C++ MPI 5 procesów standaryzacja& 5.267 \\
\hline C++ MPI 6 procesów standaryzacja& 5.259 \\ 
\hline C++ MPI 7 procesów standaryzacja& 4.841 \\ 
\hline C++ MPI 8 procesów standaryzacja& 4.542 \\
\hline
\hline Pyhon sklearn 1 wątek standaryzacja& 0.208 \\
\hline Pyhon sklearn 2 wątki standaryzacja& 0.326 \\
\hline Pyhon sklearn 3 wątki standaryzacja& 0.329 \\
\hline Pyhon sklearn 4 wątki standaryzacja& 0.328 \\\hline
\end{tabular}
\paragraph{}
Użycie MPI w c++ przyniosło pozytywny skutek. Wyniki były niemal identyczne dla danych po normalizacji jak i standaryzacji. Już przy użyciu dwóch procesów czas zmniejszył się około dwukrotnie, przy użyciu 4 procesów prawie czterokrotnie. Wykorzystanie większej ilości wątków niż 4 (liczba rdzeni procesora na którym wykonywały się obliczenia) przynosiła już niewielkie spadki lub czasami podniesienie się czasu wykonania. 
W przypadku Python zwiększanie parametru njobs algorytmu KNN przynosiło odwrotny skutek do oczekiwanego - czas wykonania wydłużał się.
\paragraph{}
\begin{tikzpicture}[scale=1.5]
\begin{axis}[
title={Zależność czasu od ilości procesów - knn},
title style={text width=16em},
xlabel={Ilość procesów},
ylabel={Czas [s]},
xmin=0,xmax=9,
ymin=4,ymax=19,
legend pos=north east,
ymajorgrids=true,grid style=dashed
]
\addplot[color=red,mark=*]
coordinates {
(1,16.673)
(2,8.531)
(3,6.299)
(4,5.536)
(5,5.470)
(6,5.283)
(7,5.069)
(8,4.661)
};

\addplot[color=green,mark=o]
coordinates {
(1,16.638)
(2,8.631)
(3,6.136)
(4,5.081)
(5,5.267)
(6,5.259)
(7,4.841)
(8,4.542)
};

\legend{C++ normalizacja, C++ standardyzacja}
\end{axis}
\end{tikzpicture}

\paragraph{}
\begin{tikzpicture}[scale=1.5]
\begin{axis}[
title={Zależność czasu od parametru njobs - knn},
title style={text width=16em},
xlabel={njobs},
ylabel={Czas [s]},
xmin=0,xmax=5,
ymin=0.15,ymax=0.56,
legend pos=north east,
ymajorgrids=true,grid style=dashed
]

\addplot[color=blue,mark=square]
coordinates {
(1,0.215)
(2,0.323)
(3,0.455)
(4,0.386)

};

\addplot[color=orange,mark=square*]
coordinates {
(1,0.208)
(2,0.326)
(3,0.329)
(4,0.328)

};

\legend{Python min-max, Python standard scaler}
\end{axis}
\end{tikzpicture}
 
\end{document}